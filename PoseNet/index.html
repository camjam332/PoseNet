<!DOCTYPE html>
<html>
  <head>
    	<!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
    <!-- Load BodyPix -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>
     <meta charset="utf-8"/>
 </head>

  <body id='body'>
    <video width=640 height=480 autoplay muted id="video">
    </video>
    <canvas id='canvas' width="640" height="480"></canvas>

    <p id="text"></p>

    <script type="text/javascript">
    var isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
    var element = document.getElementById('text');
    if (isMobile) {
        element.innerHTML = "You are using Mobile";
    } else {
      element.innerHTML = "You are using Desktop";
    }
    </script>

  </body>
  <!-- Place your code in the script tag below. You can also use an external .js file -->
  <script>

    function live_webcam()
    {
      var video = document.getElementById('video')
      // capture live video stream from web camera
      if(navigator.mediaDevices.getUserMedia)
      {
        navigator.mediaDevices.getUserMedia({video: true})
          .then(function (stream) {video.srcObject = stream; });
      }
    }

    live_webcam();

    document.getElementById("body").addEventListener("click", loadAndPredict);

    async function loadAndPredict() {

          async function step() {

              var canvas = document.getElementById('canvas');


              const net = await bodyPix.load({
              architecture: 'MobileNetV1',
              outputStride: 16,
              multiplier: 0.75,
              quantBytes: 2
              });

              //var forgroundColor 
              //forgroundColor = {r: 255, g: 255, b: 255, a: 255} 
              //const backgroundColor =  {r: 0, g: 0, b: 0, a: 255} 
              const segmentation = await net.segmentPerson(video, {
              flipHorizontal: false,
              internalResolution: 'medium',
              segmentationThreshold: 0.7
              });

              //console.log(array)

              //var forgroundColor = {r: 255, g: 0, b: 0, a: 255} 
              var backgroundColor =  {r: 0, g: 0, b: 0, a: 255} 

              const coloredPartImage = bodyPix.toMask(segmentation);
              const opacity = 0.25;
              const flipHorizontal = false;
              const maskBlurAmount = 0;

              var ctx = canvas.getContext('2d');
              //ctx.putImageData(coloredPartImage, 0, 0);
              ctx.drawImage(video, 0, 0);
              imageData = ctx.getImageData(0, 0, video.width, video.height);
              buffer = imageData.data,
              len = buffer.length,
              j = 0;
              for(; j < len; j += 4) {
              buffer[j] = 255 - buffer[j];
              buffer[j+1] = 255 - buffer[j+1];
              buffer[j+2] = 255 - buffer[j+2];              
              }
              ctx.putImageData(imageData, 0, 0);

// Draw the mask image on top of the original image onto a canvas.
// The colored part image will be drawn semi-transparent, with an opacity of
// 0.7, allowing for the original image to be visible under.
              //ctx.putImageData(imageData, 0, 0);              

              bodyPix.drawMask(
              canvas, video, coloredPartImage, opacity, maskBlurAmount,
              flipHorizontal);

            requestAnimationFrame(step)
        }
        requestAnimationFrame(step);
    }
  </script>
</html>